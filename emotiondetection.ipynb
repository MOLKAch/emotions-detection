{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzL1CeX_-T81"
      },
      "outputs": [],
      "source": [
        "#cnn here is used"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iMEmzntmV56",
        "outputId": "2746ad02-de9f-430b-b7db-36eb7b1628a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D ,MaxPooling2D,Dense,Dropout,Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "4yjtLc9A-coy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "58d93f9a-1db7-4e79-9894-77d22ce3d699"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.10/dist-packages/keras/api/preprocessing/image/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-95dc1d72189b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.10/dist-packages/keras/api/preprocessing/image/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen=ImageDataGenerator(rescale=1./255)\n",
        "validation_data_gen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "_f7aShjLCxIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator=train_data_gen.flow_from_directory('/content/drive/MyDrive/emotions/train',\n",
        "                                                   target_size=(48,48),\n",
        "                                                   batch_size=64,\n",
        "                                                   color_mode=\"grayscale\",\n",
        "                                                   class_mode=\"categorical\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42mwSaaaC_KW",
        "outputId": "660568e3-a303-444e-e591-2c2d8b93c535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28778 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import dropout\n",
        "validation_generator=validation_data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/emotions/test',\n",
        "    target_size=(48,48),\n",
        "    batch_size=64,\n",
        "    color_mode='grayscale',\n",
        "    class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QZZwd6_0l9M",
        "outputId": "d8d1be48-243f-4fa4-ff15-75db37075445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7188 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "k8oM9aN-teG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model=Sequential()\n",
        "emotion_model.add(Conv2D(32,kernel_size=(3,3),input_shape=(48,48,1),activation='relu'))\n",
        "emotion_model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "\n",
        "emotion_model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "emotion_model.add(MaxPooling2D((2,2)))\n",
        "emotion_model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024,activation='relu'))\n",
        "emotion_model.add(Dropout(0.5))\n",
        "#7=emotions\n",
        "emotion_model.add(Dense(7,activation='softmax'))\n",
        "\n",
        "\n",
        "emotion_model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "OwZj2p9cDwNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "emotion_model_info=emotion_model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=28709//64,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=7178//64\n",
        ")\n",
        "\n",
        "#save model structure in jasopn file\n",
        "model_json=emotion_model.to_json()\n",
        "with open(\"emotion_model.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "#save trained model weight in .h5 file\n",
        "emotion_model.save_weights('emotion_mode.h5')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wl0JgKXxg8bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd91297d-1e26-4bbb-b11b-3f1d27c23fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-dda76cbec2d6>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  emotion_model_info=emotion_model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140/448 [========>.....................] - ETA: 1:31:53 - loss: 1.8289 - accuracy: 0.2507"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import  cv2\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n"
      ],
      "metadata": {
        "id": "LSu7cpcY8A-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_dict={0:\"Angry\",1:\"Disgusted\",2:\"Fearful\",3:\"Happy\",4:\"Neutral\",5:\"Sad\",6:\"Suprised\"}\n"
      ],
      "metadata": {
        "id": "vQZH-SB68Krk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#oad json and create model\n",
        "json_file=open('emotion_model.json','r')\n",
        "loaded_model_json=json_file.read()\n",
        "json_file.close()\n",
        "emotion_model=model_from_json(loaded_model_json)\n",
        "#load weights into new model\n",
        "emotion_model.load_weights('/content/emotion_mode.h5')\n",
        "print(\"loaded model from disk\")"
      ],
      "metadata": {
        "id": "U5cuiGwxX6me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start the webcam\n",
        "from google.colab.patches import cv2_imshow\n",
        "#cap=cv2.VideoCapture(0)\n",
        "cap=cv2.VideoCapture(\"emotions/samples/istockphoto-1152822473-640_adpp_is.mp4\")\n",
        "while True:\n",
        "  ret,frame=cap.read()\n",
        "  frame=cv2.resize(frame,(1280,720))\n",
        "  if not ret:\n",
        "    break\n",
        "  face_detector=cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')\n",
        "  gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
        "  #detect fzces available on cam\n",
        "  num_faces=face_detector.detectMultiScale(gray_frame,scaleFactor=1.3,minNeighbors=5)\n",
        "  #take each face available on the camera and preprocess it\n",
        "  for(x,y,w,h) in num_faces:\n",
        "    cv2.rectangle(frame,(x,y-50),(x+w,y+h+10),(0,255,0),4)\n",
        "    roi_gray_frame=gray_frame[y:y+h,x:x+w]\n",
        "    cropped_img=np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame,(48,48)),-1),0)\n",
        "    #predict the emotions\n",
        "    emotion_prediction=emotion_model.predict(cropped_img)\n",
        "    maxindex=int(np.argmax(emotion_prediction))\n",
        "    cv2.putText(frame,emotion_dict[maxindex],(x+5,y-20),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
        "\n",
        "\n",
        "  cv2_imshow(frame)\n",
        "  if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
        "    break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UlY2_euGX6ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qfr9o4vWX6sY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}